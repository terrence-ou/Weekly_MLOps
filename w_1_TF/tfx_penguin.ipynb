{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4e8bfd-83e0-450a-8272-09266cbf98ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.11.0\n",
      "tfx version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tfx import v1 as tfx\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"tfx version: {tfx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d39983-1a97-4ea0-af80-d2b7875c9c7c",
   "metadata": {},
   "source": [
    "# 1. Set up pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21bba8e-d451-4363-9690-9b029a2564e5",
   "metadata": {},
   "source": [
    "## Setting up pipeline variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9088b1b3-2281-439c-a504-3ee05f6e4586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from absl import logging\n",
    "\n",
    "PIPELINE_NAME = \"penguin-simple\"\n",
    "\n",
    "PIPELINE_ROOT = os.path.join(\"pipelines\", PIPELINE_NAME)\n",
    "METADATA_PATH = os.path.join(\"metadata\", PIPELINE_NAME, \"metadata.db\")\n",
    "SERVING_MODEL_DIR = os.path.join(\"serving_model\", PIPELINE_NAME)\n",
    "\n",
    "logging.set_verbosity(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e27eee-10e1-4b4b-a66d-9487c715b926",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download example data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931cce2-591e-463d-8c58-36addedad416",
   "metadata": {},
   "source": [
    "We will download the example dataset for use in our TFX pipeline. The dataset we are using is Palmer Penguins dataset which is also used in other TFX examples.\n",
    "\n",
    "There are four numeric features in this dataset:\n",
    "\n",
    "- culmen_length_mm\n",
    "- culmen_depth_mm\n",
    "- flipper_length_mm\n",
    "- body_mass_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f1f3b4-e080-4512-b1b2-ffd28b7d8402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# import tempfile\n",
    "\n",
    "# DATA_ROOT = tempfile.mkdtemp(prefix=\"tfx-data\") # Creating a temporary directory\n",
    "# _data_url = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
    "# _data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
    "# urllib.request.urlretrieve(_data_url, _data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff538262-7fb2-4145-9461-24cda3af3b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(_data_filepath) as f:\n",
    "#     for _ in range(5):\n",
    "#         print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7f4e6d-a66a-44ba-b429-762ed444cdcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = os.path.join(\"data.csv\")\n",
    "Path(DATA_ROOT).touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81257b79-0928-47df-832b-6e59ba375080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "with open(DATA_ROOT, \"wb\") as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49783f30-ccd7-48dc-8cbd-b43700b8eb40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species,culmen_length_mm,culmen_depth_mm,flipper_length_mm,body_mass_g\n",
      "\n",
      "0,0.2545454545454545,0.6666666666666666,0.15254237288135594,0.2916666666666667\n",
      "\n",
      "0,0.26909090909090905,0.5119047619047618,0.23728813559322035,0.3055555555555556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_ROOT) as f:\n",
    "    for _ in range(3):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a81e95-baa5-4e93-b26e-29afad34faff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_train_module_file=\"penguin_trainer.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aded74-5e4d-4b2d-a703-537fab31c299",
   "metadata": {},
   "source": [
    "## Create a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92994d1-35a2-4dfd-8552-6c15dd1ff3fd",
   "metadata": {},
   "source": [
    "A pipeline consists of following three components:\n",
    "- **[CsvExampleGen](https://www.tensorflow.org/tfx/guide/examplegen)**: Reads in data files and convert them to TFX internal format for further processing\n",
    "- **[Trainer](https://www.tensorflow.org/tfx/guide/trainer)**: Trains an ML model\n",
    "- **[Pusher](https://www.tensorflow.org/tfx/guide/pusher)**: Copies the trained model outside of the TFX pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "734d0e1e-ea6f-4c74-9eed-1c723fe8a75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "    \n",
    "    \"\"\"Creating a three-component penguin pipeline with TFX\"\"\"\n",
    "    \n",
    "    # Brings data into the pipeline\n",
    "    example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "    \n",
    "    # Uses user-provided Python function that trains a model\n",
    "    trainer = tfx.components.Trainer(\n",
    "        module_file=module_file,\n",
    "        examples=example_gen.outputs[\"examples\"],\n",
    "        train_args=tfx.proto.TrainArgs(num_steps=100),\n",
    "        eval_args=tfx.proto.EvalArgs(num_steps=5)\n",
    "    )\n",
    "    \n",
    "    # Pushes the model to a filesystem destination\n",
    "    pusher = tfx.components.Pusher(\n",
    "        model=trainer.outputs[\"model\"],\n",
    "        push_destination=tfx.proto.PushDestination(\n",
    "            filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "                base_directory=serving_model_dir))\n",
    "    )\n",
    "    \n",
    "    # Include all three components into one pipeline\n",
    "    components = [\n",
    "        example_gen,\n",
    "        trainer,\n",
    "        pusher,\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    return tfx.dsl.Pipeline(\n",
    "        pipeline_name=pipeline_name,\n",
    "        pipeline_root=pipeline_root,\n",
    "        metadata_connection_config=tfx.orchestration.metadata.sqlite_metadata_connection_config(metadata_path),\n",
    "        components=components\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce03e7-9498-4d83-85d7-4ecbccbb400a",
   "metadata": {},
   "source": [
    "# 2. Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4d3f5-ac8b-4980-96ca-c536f8f7c373",
   "metadata": {},
   "source": [
    "TFX supports multiple orchestrators to run pipelines.\n",
    "In this tutorial we will use `LocalDagRunner` which is included in the TFX\n",
    "Python package and runs pipelines on local environment.\n",
    "We often call TFX pipelines \"DAGs\" which stands for directed acyclic graph.\n",
    "\n",
    "See\n",
    "[TFX on Cloud AI Platform Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines)\n",
    "or\n",
    "[TFX Airflow Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/airflow_workshop)\n",
    "to learn more about other orchestration systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724acc68-4789-41dc-a92d-910bf66eaf5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Caution: there is a path issue running the following code:\n",
    "# The TFX does not have path support on Windows OS\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(\n",
    "    _create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        data_root=DATA_ROOT,\n",
    "        module_file=_train_module_file,\n",
    "        serving_model_dir=SERVING_MODEL_DIR,\n",
    "        metadata_path=METADATA_PATH\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37a064-90e8-4dd5-b44d-221364e8c138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
